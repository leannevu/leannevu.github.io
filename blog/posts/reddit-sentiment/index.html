<!doctype html>
<html>
<head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>Leanne Vu â€” Blog</title>
    <link rel="preconnect" href="https://fonts.googleapis.com" />
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
    <link href="https://fonts.googleapis.com/css2?family=Poppins:wght@300;400;600&display=swap" rel="stylesheet" />
    <link rel="stylesheet" href="../posts.css" />
</head>
<body>
  <header class="site-header">
    <div class="container header-inner">
      <a class="brand" href="/">
        <img class="avatar" src="../../../assets/leanne-vu.jpg" alt="Leanne Vu" />
        <div>
          <div class="brand-name">Leanne Vu</div>
          <div class="brand-tagline">
            Writing about data, product, and building practical analytics.
          </div>
        </div>
      </a>

      <nav class="top-nav">
        <a href="/leannevu.github.io/index.html">Portfolio</a>
        <a href="../../index.html">Blog</a>
      </nav>
    </div>
  </header>
  <main id="content" class="wrap">
    <div class="blog-layout">

        <div class="doc-wrap">
          <article class="doc-post">
            <div class="c21 doc-content">
            <div>
                <p class="c5"><span class="c3"></span></p>
            </div>
            <p class="c10 title" id="h.fxylkjlls42"><span class="c24 c13 c28 c39">Do Reddit Sentiments Reflect Economic
                    Reality?</span></p>
            <p class="c38 subtitle" id="h.13zljn7o50xl"><span class="c41"><br></span>
            <p class="subtitle"><span class="subhead" id="subheading">Blending Statistical Inference and Predictive Modeling for
                    Economic Sentiment Analysis</span><br><span class="byline">Leanne Vu<br>December 16, 2025</span></p>
            <hr style="page-break-before:always;display:none;">
            </p>
            <p class="c36 subtitle" id="h.z9zalf4qwsrg"><span class="c3"></span></p>
            <p class="c6 c27"><span>The foundation of data mining is selecting appropriate models and understanding
                    their predictive performance. Recall there are two cultures of modeling according to Professor
                    Breiman: statistical inference or generative modeling and prediction or predictive modeling. For
                    this project, public Reddit posts are classified as either negative, neutral, or positive and aimed
                    to compare the country&rsquo;s attitude to economic trends like housing prices or unemployment
                    rates. To predict sentiment from raw posts, however, it&rsquo;s important the right model and
                    features are selected for credibility in classifying and quantifying posts. This project
                    encapsulates a blend between generative modeling and predictive modeling. Statistical inference is
                    used to evaluate the relationships between textual features and sentiment labels, guiding the
                    feature selection. Predictive models, including logistic regression and random forests, are trained
                    using these features to classify public posts by sentiment. The integration of the two modeling
                    cultures is guided by the research question: </span><span class="c13 c19">do public attitudes
                    (captured through Reddit) </span><span class="c19 c13 c2">reflect or predict</span><span
                    class="c24 c19 c13">&nbsp;real-world economic trends or policy effects?</span></p>
            <p class="c5 c27"><span class="c19 c13 c24"></span></p>
            <h1 class="c11" id="h.1ivn9olyl8ak"><span>Introduction - T</span><span class="c13">he </span><span
                    class="c13">Proble</span><span class="c9">m Statement </span></h1>
            <p class="c6"><span>The iterative process between cleaning, extracting, and running models through different
                    features is inherently not a linear process. To ensure rapid experimentation and completing the
                    sentiment analysis with a variety of different datasets, features, and proper usage of models, a
                    sample of four different datasets were finalized. The sample datasets and pipeline can be considered
                    as an early prototype demonstrating the evolution of the modeling process. Differentiating sentiment
                    from different cultures of social media platforms, topics of conversation, and emotions like sarcasm
                    or humor are challenges that long-standing research communities continue to address, each with its
                    own specialized goals. Creating a sentiment pipeline specifically for platforms like Reddit, and
                    classifying conversations relating to economic realities, is the heart of this project. &nbsp;
                </span></p>
            <h1 class="c11" id="h.vgkhfrewdxk0"><span>1</span><span>&nbsp;Exploratory Analysis</span></h1>
            <p class="c6"><span class="c9">1.1 Dataset Sources</span></p>
            <p class="c6"><span>All results reported in this paper are based on the sample training and test datasets
                    (800 and 200 samples, respectively), and an additional set combining all datasets (4000 samples).
                </span><span class="c3">The subsets below, reflect the performance between three different sets of
                    feature extraction and a glimpse of downsampling logic.</span></p>
            <p class="c6"><span class="c16 c22 c2"><a class="c20"
                        href="https://www.google.com/url?q=https://www.kaggle.com/datasets/vijayj0shi/reddit-dataset-with-sentiment-analysis/data&amp;sa=D&amp;source=editors&amp;ust=1765933959009064&amp;usg=AOvVaw0zS_D1Mg3L43znwYOa6G_E">Joshi</a></span><span
                    class="c2">&nbsp;Dataset </span><span class="c3">&mdash; Is a sentiment classified dataset
                    containing raw reddit extractions, uploaded by Vijay Joshi on Kaggle</span></p>
            <p class="c6"><span class="c16 c22 c2"><a class="c20"
                        href="https://www.google.com/url?q=https://huggingface.co/datasets/MoritzLaurer/sentiment_economy_news&amp;sa=D&amp;source=editors&amp;ust=1765933959009590&amp;usg=AOvVaw3Vq3GsO4i9eWY1Y-e8WImX">La
                    </a></span><span class="c2">Dataset </span><span class="c3">&mdash; Is a sentiment classified
                    dataset, containing &nbsp;&lsquo;News Headlines&rsquo; text, uploaded by Moritz Laurer on Hugging
                    Face.</span></p>
            <p class="c6"><span class="c16 c22 c2"><a class="c20"
                        href="https://www.google.com/url?q=https://www.kaggle.com/datasets/cosmos98/twitter-and-reddit-sentimental-analysis-dataset/data?select%3DTwitter_Data.csv&amp;sa=D&amp;source=editors&amp;ust=1765933959010214&amp;usg=AOvVaw2zd4n-YVSN1zDA0y_ByEtH">Kumar
                    </a></span><span class="c2">Dataset </span><span class="c3">&mdash; Is a sentiment classified
                    dataset containing text posted on Reddit and Twitter, uploaded by &nbsp;Chaithanya Kumar A on
                    &nbsp;Kaggle</span></p>
            <p class="c6"><span class="c16 c2 c22"><a class="c20"
                        href="https://www.google.com/url?q=https://github.com/mashe0742/CMSC495_Proj/tree/main/RedditSentimentAnalysis&amp;sa=D&amp;source=editors&amp;ust=1765933959010777&amp;usg=AOvVaw0YN1lQY0UUnm0i2MyGWtyg">Mashe
                    </a></span><span class="c2">Dataset</span><span class="c3">&nbsp;&mdash; Is a sentiment classified
                    dataset, predicted with BERT model for Reddit posts on a timely basis, uploaded by Michael Mashe on
                    Github</span></p>
            <p class="c6"><span class="c2">Combined Dataset </span><span class="c3">&mdash; Is a combination of all
                    datasets, as a form of mild cross validation</span></p>
            <p class="c6"><span>The original datasets were relatively clear from duplicates and NA. The majority of
                    cleaning datasets involved removing leading and trailing white spaces, website links, and columns
                    that don&rsquo;t contain text or sentiment values. All columns were renamed and ordered to the
                    respective labels [&lsquo;sentiment&rsquo;, &lsquo;text&rsquo;] and sentiment values were renamed
                    with respect to their meaning [&lsquo;positive&rsquo;, &lsquo;neutral&rsquo;,
                    &lsquo;negative&rsquo;] &nbsp;(</span><span class="c2">see figure 2</span><span class="c3">) for
                    cleaning. </span></p>
            <p class="c6"><span class="c3">As for class imbalances with sentiment labeling, the datasets were
                    downsampled in two ways:</span></p>
            <ol class="c23 lst-kix_c2ke7enwh8go-0 start" start="1">
                <li class="c1 li-bullet-0"><span>Downsample logic 1 aims to combine all the datasets, retaining as much
                        data as possible, while balancing sentiment class distribution as a whole. Due to
                        disproportionate sizes, this requires minimizing &lsquo;Positive&rsquo; and
                        &lsquo;Negative&rsquo; sentiment labels in Kumar&rsquo;s dataset to offset the missing
                        &lsquo;Neutral&rsquo; sentiment in La and Joshi datasets (</span><span class="c2">see figures 4
                        and 5</span><span class="c3">).</span></li>
                <li class="c1 li-bullet-0"><span>Downsample logic 2 aims to cut off each dataset to 1000 samples,
                        minimizing possible bias from disproportionate sample sizes and a balanced distribution within
                        each dataset for sentiment values that are available (</span><span class="c2">see figure
                        3</span><span class="c3">). </span></li>
            </ol>
            <p class="c6"><span>For the sake of this project, downsample logic 2 is used as a means to quickly evaluate
                    and evolve feature engineering practices. Following downsampling, train and test splits are
                    constrained to sentiment proportions, ready to begin the pipeline (</span><span class="c2">see
                    figure 1</span><span class="c3">) for modeling.</span></p>
            <p class="c5"><span class="c3"></span></p>
            <p class="c6"><span
                    style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 561.98px; height: 384.00px;"><img
                        alt="" src="./images/image14.png"
                        style="width: 561.98px; height: 384.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                        title=""></span></p>
            <p class="c6 c12"><span class="c0">Figure 1&mdash;</span><span class="c15">&nbsp;Flowchart for cleaning
                    data, downsampling for model pipeline experimentation, and splitting train and test subsets in
                    respect to sentiment class balance. </span></p>
            <p class="c6"><span
                    style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 528.00px; height: 220.00px;"><img
                        alt="" src="./images/image15.png"
                        style="width: 528.00px; height: 220.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                        title=""></span></p>
            <p class="c6"><span
                    style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 355.00px; height: 472.00px;"><img
                        alt="" src="./images/image18.png"
                        style="width: 355.00px; height: 472.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                        title=""></span></p>
            <p class="c6 c12"><span class="c0">Figure 2&mdash;</span><span class="c15">&nbsp;Columns and rows of
                    original datasets before and after cleaning (no downsampling), and Sentiment distribution of
                    original datasets before and after cleaning. Kumar&rsquo;s sentiment values are renamed from [1.0,
                    0, -1.0] to [&lsquo;Positve&rsquo;, &lsquo;Neutral&rsquo;, &lsquo;Negative&rsquo;]. Kumar has the
                    largest number of rows and La has the least number of rows.</span></p>
            <p class="c6"><span
                    style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 475.00px; height: 395.00px;"><img
                        alt="" src="./images/image8.png"
                        style="width: 475.00px; height: 395.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                        title=""></span></p>
            <p class="c6"><span
                    style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 480.00px; height: 320.00px;"><img
                        alt="" src="./images/image13.png"
                        style="width: 480.00px; height: 320.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                        title=""></span></p>
            <p class="c6 c12"><span class="c0">Figure 3&mdash;</span><span class="c24 c15 c13 c28">Train and test
                    compositions of the combined dataset, and sentiment class balance for each dataset: Kumar, Joshi,
                    La, Mashe. Joshi and La did not have neutral sentiments, reflected in the balance of Combined
                    Sentiment .</span></p>
            <p class="c5 c37"><span class="c24 c15 c13 c28"></span></p>
            <p class="c26"><span
                    style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 325.00px; height: 389.11px;"><img
                        alt="" src="./images/image12.png"
                        style="width: 325.00px; height: 389.11px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                        title=""></span></p>
            <p class="c6 c12"><span class="c0">Figure 4&mdash;</span><span class="c15">&nbsp;Downsamping logic to retain
                    as much data as possible in each data set, while protecting class balance when all data sets are
                    combined. When not minimized to samples of size 1000, neutral samples are tripled in Kumar dataset
                    to offset datasets like La and Joshi that don&rsquo;t have neutral sentiments. </span></p>
            <p class="c26"><span
                    style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 466.00px; height: 233.47px;"><img
                        alt="" src="./images/image7.png"
                        style="width: 466.00px; height: 233.47px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                        title=""></span></p>
            <p class="c6 c12"><span class="c0">Figure 5&mdash;</span><span class="c24 c15 c13 c28">&nbsp;All datasets
                    combined with downsamping logic of retaining as much data as possible in each data set. &nbsp;Split
                    into subsets of 80% train and 20% test. &nbsp;</span></p>
            <p class="c5 c12"><span class="c24 c15 c13 c28"></span></p>
            <p class="c6"><span class="c9">1.2 Reddit Extraction Sources</span></p>
            <p class="c6"><span>Using the PRAW API, Reddit posts are extracted through </span><span class="c16 c22"><a
                        class="c20"
                        href="https://www.google.com/url?q=https://developers.reddit.com/&amp;sa=D&amp;source=editors&amp;ust=1765933959017726&amp;usg=AOvVaw1oXhwwp5CtUtvNEBHHSdXt">https://developers.reddit.com/</a></span><span>,
                    using their </span><span class="c3">API guidelines and registering for a token. Post retrievals were
                    from the following threads : economics, housing, finance, inflation, employment. </span></p>
            <p class="c6"><span>Cleaning involves keeping columns and renaming them to their respective values of
                    [&lsquo;text&rsquo;,&rsquo;date&rsquo;] and removing NA and duplicate values (</span><span
                    class="c2">see figure 4</span><span>). Before cleaning, overlap between datasets retrieved are
                    checked and merged where applicable (</span><span class="c2">see figure 5 and 7</span><span>).
                </span></p>
            <p class="c6"><span
                    style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 380.00px; height: 186.00px;"><img
                        alt="" src="./images/image3.png"
                        style="width: 380.00px; height: 186.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                        title=""></span></p>
            <p class="c6"><span
                    style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 398.00px; height: 193.00px;"><img
                        alt="" src="./images/image11.png"
                        style="width: 398.00px; height: 193.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                        title=""></span></p>
            <p class="c6 c12"><span class="c0">Figure 6&mdash;</span><span class="c24 c15 c13 c28">&nbsp;Columns and
                    rows of Reddit datasets before and after cleaning. </span></p>
            <p class="c6"><span
                    style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 518.72px; height: 380.00px;"><img
                        alt="" src="./images/image6.png"
                        style="width: 518.72px; height: 380.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                        title=""></span></p>
            <p class="c6 c12"><span class="c0">Figure 7&mdash;</span><span class="c24 c15 c13 c28">&nbsp;Flowchart for
                    the preparation of Reddit posts for prediction modeling; Data extracted from PRAW API had duplicate
                    files under different names. </span></p>
            <p class="c5 c12"><span class="c24 c15 c13 c28"></span></p>
            <p class="c6"><span class="c30">1.3 Feature Extraction Sources</span></p>
            <p class="c6"><span class="c16 c22 c2"><a class="c20"
                        href="https://www.google.com/url?q=https://archive.ics.uci.edu/dataset/94/spambase&amp;sa=D&amp;source=editors&amp;ust=1765933959019513&amp;usg=AOvVaw131KRaidjhCQhe3JXDf3gu">Spam
                        UCI</a></span><span class="c2">&nbsp;and </span><span class="c16 c22 c2"><a class="c20"
                        href="https://www.google.com/url?q=https://archive.ics.uci.edu/dataset/228/sms%2Bspam%2Bcollection&amp;sa=D&amp;source=editors&amp;ust=1765933959019658&amp;usg=AOvVaw2WufeJjWJ4qGl3FQK6Kjp9">SMS
                        UCI datasets</a></span><span class="c2">&nbsp;</span><span>&mdash; is used to conduct
                    performance of the spam baseline model, inspired by Spam UCI features and additional structural
                    features, discussed in</span><span class="c35 c13 c2 c28">&nbsp;2.1.</span></p>
            <p class="c6"><span class="c2">Structural Features</span><span class="c3">&nbsp;&mdash; Computed and
                    identified underlying text patterns through regex pattern matching, and computing for [average,
                    longest, and lowest capitalization runs and counts words, chars, digits, and symbols]. </span></p>
            <p class="c6"><span class="c2">Core Lexicon Features</span><span>&nbsp;&mdash; NLP Vader Sentiment Analyzer
                    model extracted [pos, neu, neg, compound] and NLP TextBlob python library extracted [polarity,
                    subjectivity] scores (</span><span class="c2">see appendix</span><span class="c3">).</span></p>
            <p class="c6"><span class="c2">Hybrid Features</span><span>&nbsp;&mdash; A mix of all </span><span
                    class="c2">structural features</span><span>, </span><span class="c2">all core lexicon
                    features</span><span>, and NLP Finbert extractions of [Negative probability, Positive probability,
                    Neutral Probability, Compound Probability based on explicit crisis or growth terms] (</span><span
                    class="c2">see appendix</span><span>).</span></p>
            <p class="c6 c12"><span class="c15">&nbsp;</span></p>
            <h1 class="c4" id="h.pmbj0cqwfcca"><span class="c14">2 Methodology</span></h1>
            <p class="c6"><span>W</span><span class="c3">orkflow is organized into three sections: </span></p>
            <h2 class="c8" id="h.ihtjzignqktr"><span>2.1 Statistic Inference and Generative Modeling for Spam and
                    Sentiment Analysis</span></h2>
            <p class="c6"><span class="c2 c30">2.1.1 Spam &mdash; </span><span>Drawing on the feature engineering
                    practices established in the UCI Email Spam dataset, this project extracted counts of
                    spam-associated words and character patterns alongside additional structural text features,
                    including average and maximum capital letter run length, total capital usage, word count, and
                    character count. To enhance applicability to non-email text sources, the feature set was further
                    expanded to capture symbol frequency, digit frequency, exclamation and question mark usage, emoji
                    presence, toxicity score (</span><span class="c2">same practice discussed in 1.3</span><span
                    class="c3">), and the number of embedded links.</span></p>
            <p class="c26"><span
                    style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 428.50px; height: 305.96px;"><img
                        alt="" src="./images/image1.png"
                        style="width: 428.50px; height: 305.96px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                        title=""></span></p>
            <p class="c6 c12"><span class="c0">Figure 8&mdash;Logistic Regression </span><span class="c15">prediction
                    errors for UCI and UCI/Structural features. The expanded feature set slightly outperforms the UCI
                    features on the UCI SMS dataset by .0409</span></p>
            <p class="c5"><span class="c3"></span></p>
            <p class="c32"><span class="c3">The logistic model was used to evaluate performance. Because the UCI
                    spambase database does not include sentiment values and primarily reports achieving a prediction
                    rate of approximately 0.95 within its own experimental context, direct comparison was not feasible.
                    To establish a meaningful benchmark, the UCI SMS Spam dataset, which contains a clear classification
                    response, was used to test the predictive value of both the original UCI Email Spam features and the
                    combined feature set. Results indicate that the extended feature set is highly capable of
                    classifying sentiment outside of emails, thereby justifying its use for preliminary spam
                    filtering.</span></p>
            <p class="c6"><span class="c9">2.1.2 Sentiment</span></p>
            <p class="c6"><span>Samples from each dataset were processed through a consistent feature extraction
                    pipeline (</span><span class="c2">see appendices 7 for implementation details</span><span
                    class="c3">). This approach enabled the removal of features that showed limited usefulness across
                    contexts. Across multiple datasets, prediction error varied substantially, reflecting differences in
                    linguistic norms, platform culture, and text formatting styles across social media sources. Initial
                    feature engineering began with lexicon-based sentiment indicators, followed by experiments combining
                    these features with various sentiment models. Feature importances were calculated for several social
                    media datasets to identify which textual characteristics contributed most consistently to predictive
                    performance.</span></p>
            <p class="c32"><span class="c3">Because prediction behavior differed widely between datasets, the analysis
                    shifted toward sources that more closely matched the style and economic context of the Reddit posts
                    intended for final evaluation. This transition led to the use of the FinBERT model and an economic
                    sentiment dataset. Although this dataset aligned more closely with the economic focus of the target
                    Reddit posts, platform-specific differences&mdash;such as writing style, community conventions, and
                    text length&mdash;remained.</span></p>
            <p class="c32"><span>The final feature set was narrowed to </span><span class="c2">Hybrid Features (see
                    1.3), </span><span>including sentiment models such as VADER and FinBERT, along with lexicon-based
                    features designed to adjust for variation in text length across platforms. This refined set of
                    features provided a more stable and adaptable foundation for analyzing sentiment in economic
                    discussions on Reddit (</span><span class="c2">see 2.2</span><span>). </span></p>
            <p class="c26"><span
                    style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 466.00px; height: 367.00px;"><img
                        alt="" src="./images/image10.png"
                        style="width: 466.00px; height: 373.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                        title=""></span></p>
            <p class="c6"><span
                    style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 500.00px; height: 200.00px;"><img
                        alt="" src="./images/image9.png"
                        style="width: 500.00px; height: 200.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                        title=""></span></p>
            <p class="c6 c12"><span class="c0">Figure 9&mdash;Heatmap and </span><span class="c15 c30">Chart
                </span><span class="c15">illustrating the most influential features within each feature
                    group&mdash;Structural, Core Lexicon, and Hybrid&mdash;under a shared Random Forest model.
                    Identifying which features carry the greatest weight within their respective groups provides insight
                    into the linguistic signals emphasized by each feature set. This type of analysis supports the
                    broader iterative feature-engineering process used throughout the project, informing decisions about
                    which features or feature groups are most promising before evaluating their performance across
                    diverse datasets.</span></p>
            <p class="c5"><span class="c9"></span></p>
            <h2 class="c8" id="h.gzbtrce3icfe"><span class="c9">2.2 Prediction and Predictive Modeling for Sentiment and
                    Spam Analysis</span></h2>
            <p class="c6"><span class="c3">Logistic Regression and Random Forest (see Appendix) were selected as the
                    primary predictive models for sentiment and spam classification. These models offer complementary
                    strengths that align well with both the structure of the engineered features, the variability of the
                    datasets, and the finalized modeling pipeline prototype to predict Reddit posts in this project.
                </span></p>
            <p class="c32"><span class="c3">In practice, the two models behaved differently across datasets. Logistic
                    Regression showed relatively stable train&ndash;test performance across all data sources, reflecting
                    its simpler linear structure. Random Forest, in contrast, frequently achieved very low training
                    error but displayed more variability in test performance, a pattern consistent with higher-capacity
                    models applied to small or noisy text datasets. Because of these differences, the modeling roles
                    were separated: Logistic Regression was assigned to spam filtering, where the decision boundary is
                    simple, while Random Forest was used for multi-class sentiment classification, where richer feature
                    interactions are beneficial.</span></p>
            <p class="c32"><span>The heterogeneity of features engineered in this project&mdash;from hard coding the
                    extraction of </span><span class="c2">structural features</span><span>, and utilizing NLP models and
                    libraries for </span><span class="c2">core lexicon features</span><span>, and </span><span
                    class="c2">hybrid features</span><span>&nbsp;(</span><span class="c2">see 1.3</span><span
                    class="c3">) &mdash; naturally benefits with Random Forest, capturing nonlinear thresholds and
                    multi-feature decision paths. This capability is especially important for datasets drawn from
                    diverse social media platforms, where stylistic conventions, text formatting, and linguistic
                    behaviors vary widely. These considerations are especially relevant when anticipating the
                    characteristics of Reddit data: variation in tone, formatting, length, and linguistic style,
                    especially in the context of subreddits and conversational context. An ensemble of decision trees,
                    as implemented in Random Forest, can adapt to this diversity by allowing different trees to
                    specialize in different structural or linguistic patterns. </span></p>
            <p class="c32"><span class="c3">To emphasize feature generalization rather than optimization of a single
                    model configuration, the pipeline held classifier settings constant while comparing performance
                    across datasets differing in platform culture, text style, and linguistic variability. This approach
                    reflects the core goal of the project: to evaluate whether engineered features (structural, lexicon,
                    and Hybrid Features) generalize across different linguistic domains.</span></p>
            <p class="c26"><span
                    style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 486.50px; height: 650.09px;"><img
                        alt="" src="./images/image17.png"
                        style="width: 486.50px; height: 650.09px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                        title=""></span></p>
            <p class="c6 c12"><span class="c0">Figure 11&mdash;</span><span class="c15 c30">Random Forest
                    Tree</span><span class="c15">&nbsp;results in Macro F1, Weighted F1, and Prediction Error for
                    Structure, Core, and Hybrid feature sets across all sample datasets. Performance levels vary across
                    datasets due to differences in writing style and platform conventions, but Hybrid Features
                    consistently achieve the highest scores. The figure highlights how linguistic variability affects
                    overall difficulty while preserving the same feature-set ranking.</span></p>
            <p class="c32"><span>Macro F1 and Weighted F1 were reported to provide class-level insight into sentiment
                    prediction performance, especially in datasets with class imbalance. Macro F1 treats each sentiment
                    category equally, while Weighted F1 accounts for class frequency. These metrics were chosen because
                    accuracy alone can obscure whether minority sentiment classes (positive, neutral, or negative) are
                    being predicted well.</span></p>
            <h2 class="c7" id="h.8nz8is8ilfj6"><span class="c9">2.3 Statistical Inference on Predicted Sentiment and
                    Economic Trends</span></h2>
            <p class="c32"><span class="c3">The finalized pipeline&mdash;consisting of Logistic Regression for spam
                    filtering and a Random Forest classifier applied to the Hybrid Feature set for multi-class sentiment
                    prediction&mdash;successfully generated sentiment estimates for Reddit posts despite the constraints
                    of limited and temporally clustered data.</span></p>
            <p class="c31"><span class="c3">The final stage of this project applies the modeled sentiment labels to a
                    recent collection of Reddit posts and comments related to economics, housing, finance, inflation,
                    and employment (see figure 12). </span></p>
            <p class="c31"><span>To explore potential relationships between public sentiment and real-world economic
                    conditions, predicted sentiment was aligned with monthly macroeconomic indicators obtained through
                    the Federal Reserve Economic Data (FRED) API, specifically unemployment rates (UNRATE) and the Job
                    Openings Rate (JTSJOR). These indicators were selected because they represent broad labor-market
                    conditions that often drive public concern around affordability, housing, and financial stability.
                </span></p>
            <p class="c26"><span
                    style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 479.50px; height: 502.18px;"><img
                        alt="" src="./images/image2.png"
                        style="width: 479.50px; height: 502.18px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                        title=""></span></p>
            <p class="c6 c12"><span class="c0">Figure 12&mdash;</span><span class="c24 c15 c13 c28">Pipeline prototype
                    for Reddit sentiment classification, producing a time-stamped sequence of predicted sentiment values
                    reflecting public economic discussions across Reddit.</span></p>
            <p class="c5 c12"><span class="c24 c15 c13 c28"></span></p>
            <p class="c31"><span class="c3">The objective of this section is not to establish definitive causal
                    relationships, but rather to assess whether meaningful alignment exists between economic events and
                    shifts in public sentiment. The initial research questions continue to guide the exploratory
                    analysis: </span></p>
            <p class="c25"><span class="c3">Do negative discussions spike when housing prices rise or affordability
                    drops?</span></p>
            <ul class="c23 lst-kix_cl3w0t1wdk1n-0 start">
                <li class="c17 li-bullet-0"><span class="c3">Have there been drastic changes in the United States
                        economy and is this change reflected in the media as well?</span></li>
                <li class="c17 li-bullet-0"><span>Does sentiment </span><span class="c2">lead</span><span
                        class="c3">&nbsp;the economic trend (predictive power)?</span></li>
            </ul>
            <ul class="c23 lst-kix_cl3w0t1wdk1n-1 start">
                <li class="c25 c18 li-bullet-0"><span class="c3">Housing prices</span></li>
                <li class="c25 c18 li-bullet-0"><span class="c3">Bureau of Labor Statistics (BLS)
                        Employment/Unemployment rates</span></li>
            </ul>
            <p class="c5 c37"><span class="c24 c15 c13 c28"></span></p>
            <h1 class="c4" id="h.1ob5komhk1mq"><span class="c29">3 Analysis and Results</span></h1>
            <h2 class="c8" id="h.brvvjbbt2ikh"><span class="c9">3.1 Model Results</span></h2>
            <p class="c6"><span>Across datasets, Hybrid Features consistently produced the strongest performance,
                    achieving the highest Macro F1, Weighted F1, and lowest prediction error in every sample. However,
                    the </span><span>magnitude </span><span class="c3">of these gains varied by dataset due to
                    differences in writing style, text length, and platform conventions. Reddit-like datasets (Joshi,
                    Kumar, Mashe) showed the largest improvements when Hybrid Features were used, reflecting their
                    longer, informal, and linguistically varied text. In contrast, the La dataset&mdash;composed of
                    short, highly standardized news headlines&mdash;showed smaller gains. Although this dataset is
                    related to financial news, its headline-style phrasing provides limited contextual and structural
                    cues for FinBERT and other Hybrid Features to leverage, reducing the benefit of the richer feature
                    set. Overall, the results indicate that while Hybrid Features generalize well across domains, the
                    degree of improvement is strongly influenced by each dataset&rsquo;s linguistic characteristics. As
                    such, the Random Forest results should be interpreted as a demonstration of feature-engineering
                    strategies and cross-dataset comparison.</span></p>
            <h2 class="c8" id="h.d7cbree0wsqp"><span class="c9">3.2 Prototype Pipeline Results</span></h2>
            <p class="c6"><span class="c3">The finalized pipeline&mdash;consisting of Logistic Regression for spam
                    filtering and a Random Forest classifier applied to the Hybrid Feature set for multi-class sentiment
                    prediction&mdash;successfully generated sentiment estimates for Reddit posts despite the constraints
                    of limited and temporally clustered data.</span></p>
            <p class="c6"><span class="c3">Although an inverse pattern appears&mdash;sentiment increasing as
                    unemployment declines and dropping sharply at the end&mdash;these fluctuations likely reflect data
                    sparsity and extraction limitations rather than meaningful economic signals. The PRAW API
                    doesn&rsquo;t permit retrieval of posts by timestamp, which led to heavily clustered within recent
                    months, resulting in a restricted, uneven, and relatively small sample. This constraint, combined
                    with class imbalance within the sentiment labels, results in a noisy sentiment trend that cannot
                    accurately describe economic patterns.</span></p>
            <p class="c32"><span class="c3">As a result, the findings should be interpreted primarily as a demonstration
                    of the end-to-end modeling pipeline rather than as supporting evidence of any underlying economic
                    relationship. Future work using larger, time-balanced datasets would be required to investigate the
                    hypotheses.</span></p>
            <p class="c5"><span class="c3"></span></p>
            <p class="c26"><span
                    style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 310.00px; height: 308.04px;"><img
                        alt="" src="./images/image4.png"
                        style="width: 310.00px; height: 308.04px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                        title=""></span></p>
            <p class="c6 c12"><span class="c0">Figure 13 &mdash; </span><span class="c15">Reddit posts prediction
                    results - composition of classification results for number of posts retrieved. More than half of
                    posts were classified as spam, Neutral dominated sentiment labeling and Negative was least
                    classified.</span></p>
            <p class="c26"><span
                    style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 404.43px; height: 247.50px;"><img
                        alt="" src="./images/image16.png"
                        style="width: 404.43px; height: 247.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                        title=""></span></p>
            <p class="c6 c12"><span class="c0">Figure 14&mdash;</span><span class="c15">&nbsp;Reddit posts prediction
                    results, relative to date posted. The majority of posts retrieved were posted in 2025. </span></p>
            <p class="c5 c12"><span class="c24 c15 c13 c28"></span></p>
            <p class="c26"><span
                    style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 435.50px; height: 214.98px;"><img
                        alt="" src="./images/image5.png"
                        style="width: 435.50px; height: 214.98px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);"
                        title=""></span></p>
            <p class="c6 c12"><span class="c0">Figure 15&mdash;</span><span class="c15">Average posts prediction
                    results, relative to date posted and unemployment rate retrieved from Federal Reserve Economic Data.
                </span></p>
            <h1 class="c4" id="h.j2ceh8yzupye"><span class="c14">4 Lessons Learned</span></h1>
            <p class="c6"><span class="c3">I took on the scope of this project with the intention of familiarizing
                    myself with how data mining pipelines work from end to end and developing a deeper, practical
                    understanding of applied analytics. I started with an ambitious proposal and dove right in,
                    extracting reddit posts, working with datasets (many of which I decided to not use) and
                    experimenting with how I wanted to position models in the pipeline. </span></p>
            <p class="c6"><span class="c3">Considering the scope of the project, the timeline, and my initial knowledge
                    with sentiment analysis and open source libraries, the biggest takeaway for me is to not overpromise
                    on a deadline. I spent a lot of time learning how open source models work, variations in sentiment
                    analysis, extracting Reddit posts, and automating workflows after repeatedly finding myself coding
                    or testing the same things in different variations. </span></p>
            <p class="c6"><span class="c3">I also could&rsquo;ve saved a lot of time if I kept track of meta data,
                    rather than gathering it near the end of the project. Small things like that would&rsquo;ve helped
                    me come up with automations quicker, envision exactly what I needed, and would&rsquo;ve relieved a
                    lot of time with problem solving and finalizing my findings. </span></p>
            <p class="c6"><span class="c3">In terms of technicality, I&rsquo;ve grown a deeper understanding of the
                    capabilities with Python, and efficiently &nbsp;organizing, extracting, and plotting data as I need.
                    Incorporating different models for different purposes (like Linear Regression for spam detection,
                    Finbert for economic contextualized text), and recognizing and creating patterns early, are all
                    important for the sake of automation and experimenting with different datasets in a domain that
                    I&rsquo;m not strong in. </span></p>
            <h1 class="c4" id="h.abtrpam8ft2o"><span class="c29">5 </span><span class="c14">Bibliography and
                    Credits</span></h1>
            <ol class="c23 lst-kix_lpiyrfwbxzee-0 start" start="1">
                <li class="c1 li-bullet-0"><span>Araci, D. (2019). </span><span class="c2">FinBERT: Financial sentiment
                        analysis with pre-trained language models</span><span>. arXiv.</span><span><a class="c20"
                            href="https://www.google.com/url?q=https://arxiv.org/abs/1908.10063&amp;sa=D&amp;source=editors&amp;ust=1765933959047409&amp;usg=AOvVaw2120To6d2GQPeb864JUK8M">&nbsp;</a></span><span
                        class="c16"><a class="c20"
                            href="https://www.google.com/url?q=https://arxiv.org/abs/1908.10063&amp;sa=D&amp;source=editors&amp;ust=1765933959047554&amp;usg=AOvVaw3YC9eyKKwNDkGXeKj4j9mE">https://arxiv.org/abs/1908.10063</a></span>
                </li>
                <li class="c1 li-bullet-0"><span>Burns, D. (2025, November 6). </span><span class="c2">US unemployment
                        rate rounds up to 4.4% in October, Chicago Fed estimates</span><span class="c3">. Reuters.
                        https://www.reuters.com/world/us/us-unemployment-rate-rounds-up-44-october-chicago-fed-estimates-2025-11-06/</span>
                </li>
                <li class="c1 li-bullet-0"><span>Hutto, C. J., &amp; Gilbert, E. (2014). </span><span class="c2">VADER:
                        A parsimonious rule-based model for sentiment analysis of social media text</span><span>. In
                    </span><span class="c2">Proceedings of the International AAAI Conference on Web and Social
                        Media</span><span>&nbsp;(Vol. 8, No. 1, pp. 216&ndash;225).</span><span><a class="c20"
                            href="https://www.google.com/url?q=https://ojs.aaai.org/index.php/ICWSM/article/view/14550&amp;sa=D&amp;source=editors&amp;ust=1765933959048582&amp;usg=AOvVaw3wlUnQQU6_99eGbnnRXIOa">&nbsp;</a></span><span
                        class="c16"><a class="c20"
                            href="https://www.google.com/url?q=https://ojs.aaai.org/index.php/ICWSM/article/view/14550&amp;sa=D&amp;source=editors&amp;ust=1765933959048755&amp;usg=AOvVaw3HeCe27AkG1XcrkOcqZ420">https://ojs.aaai.org/index.php/ICWSM/article/view/14550</a></span>
                </li>
                <li class="c1 li-bullet-0"><span>Malo, P., Sinha, A., Takala, P., Korhonen, P., &amp; Wallenius, J.
                        (2013). </span><span class="c2">Good debt or bad debt: Detecting semantic orientations in
                        economic texts</span><span>. arXiv.</span><span><a class="c20"
                            href="https://www.google.com/url?q=https://arxiv.org/abs/1307.5336&amp;sa=D&amp;source=editors&amp;ust=1765933959049180&amp;usg=AOvVaw3gS4UY8QpeFErMmhONcJSq">&nbsp;</a></span><span
                        class="c16"><a class="c20"
                            href="https://www.google.com/url?q=https://arxiv.org/abs/1307.5336&amp;sa=D&amp;source=editors&amp;ust=1765933959049299&amp;usg=AOvVaw1oEvKI92-CCr6nRdRUdink">https://arxiv.org/abs/1307.5336</a></span>
                </li>
                <li class="c32 c40 li-bullet-0"><span>Matsumoto, B., &amp; Stockburger, A. (2025). </span><span
                        class="c2">Measurement issues in consumer price indexes</span><span class="c3">&nbsp;(Economic
                        Working Paper No. WP-584). Office of Prices and Living Conditions.</span></li>
                <li class="c1 li-bullet-0"><span>Mohammad, S. M., &amp; Turney, P. D. (2013). </span><span
                        class="c2">Crowdsourcing a word&ndash;emotion association lexicon</span><span class="c3">.
                        Computational Intelligence, 29(3), 436&ndash;465.
                        https://doi.org/10.1111/j.1467-8640.2012.00460.x</span></li>
                <li class="c32 c40 li-bullet-0"><span>Neal Caren. (2019, May 1). </span><span class="c2">Word lists and
                        sentiment analysis</span><span>. https://nealcaren.org/lessons/wordlists/ </span></li>
                <li class="c1 li-bullet-0"><span class="c3">Newman, H. &amp; Joyner, D. A. (2018). Sentiment Analysis of
                        Student Evaluations of Teaching. In Proceedings of the 19th International Conference on
                        Artificial Intelligence in Education. London, United Kingdom. Springer.</span></li>
                <li class="c1 li-bullet-0"><span>Sok, E., Smith, S., &amp; Evans, J. (2025, September). </span><span
                        class="c2">Unemployment rate increases in the first half of 2024, before leveling off, while the
                        labor force participation rate holds fairly steady</span><span>. Monthly Labor Review, U.S.
                        Bureau of Labor Statistics. </span><span class="c16"><a class="c20"
                            href="https://www.google.com/url?q=https://doi.org/10.21916/mlr.2025.17&amp;sa=D&amp;source=editors&amp;ust=1765933959051763&amp;usg=AOvVaw2CA8U_bfPK4PBTymApKkrA">https://doi.org/10.21916/mlr.2025.17</a></span>
                </li>
                <li class="c1 li-bullet-0"><span>Visual Paradigm. (n.d.). </span><span class="c2">Flowchart
                        tutorial</span><span>. Retrieved November 22, 2025, from</span><span><a class="c20"
                            href="https://www.google.com/url?q=https://www.visual-paradigm.com/tutorials/flowchart-tutorial/&amp;sa=D&amp;source=editors&amp;ust=1765933959052257&amp;usg=AOvVaw34eGxcpNaNuEsMV6EOv2Ws">&nbsp;</a></span><span
                        class="c16"><a class="c20"
                            href="https://www.google.com/url?q=https://www.visual-paradigm.com/tutorials/flowchart-tutorial/&amp;sa=D&amp;source=editors&amp;ust=1765933959052532&amp;usg=AOvVaw0EgSLVljC_ZlHPVv0lXl95">https://www.visual-paradigm.com/tutorials/flowchart-tutorial/</a></span>
                </li>
            </ol>
            <p class="c5"><span class="c3"></span></p>
            <h1 class="c4" id="h.xmkq6u5e29m9"><span class="c29">7</span><span class="c14">&nbsp;Appendices </span></h1>
            <h2 class="c8" id="h.utkmpokrzpm"><span>7.1 Glossary of Terms</span></h2>
            <p class="c6"><span class="c3">BERT (Bidirectional Encoder Representations from Transformers): Analyzes text
                    by simultaneously contextualized left and right directions, compared to traditional NLP models that
                    contextualize left to right or right to left </span></p>
            <p class="c6"><span class="c3">Finbert: NLP model built on BERT, detecting sentiment on a financial domain
                    (economic contextualized text)</span></p>
            <p class="c6"><span class="c3">Lexicon: Collection of words with associated sentiment values</span></p>
            <p class="c6"><span class="c3">Logistic Regression: Assumes a Bernoulli distribution for the response
                    variable, where the probability of class membership is modeled directly rather than through the
                    distribution of predictors. This makes logistic regression a discriminate model, as it avoids making
                    assumptions about the relationships or independence of the predictor variables</span></p>
            <p class="c6"><span class="c3">Random Forest: Repeatedly uses the best predictor from a random subset of
                    predictors at each split of each decision tree computed. Many decision trees combined into one
                    model, aiming to minimize classification error. It captures feature importance through nonlinear
                    relationships. &nbsp;</span></p>
            <p class="c6"><span>TextBlob: Python library for general NLP use &nbsp;</span></p>
            <p class="c6"><span class="c3">UCI Spam Database: Composed of features pre extracted from a set of emails,
                    reported to have an accuracy rate of 91.920 using Logistic Regression.</span></p>
            <p class="c6"><span>UCI SMS Database: SMS messages with classified labels of &lsquo;spam&rsquo; or
                    &lsquo;ham&rsquo; </span></p>
            <p class="c6"><span class="c3">Vader: NLP model detecting sentiment using a lexicon and set of rules
                    approach on a social media domain (slang, emojis, punctuation, etc.)</span></p>
            <p class="c6"><span class="c3">Visual Studio Code: Integrated Development environment used to implement and
                    run code</span></p>
            <p class="c6"><span class="c3">Jupyter: Integrated Development Environment mainly for Python to implement
                    and run code, convenient for exploratory analysis due to ease of viewing outputs while coding (data,
                    graphs, etc.)</span></p>
            <h2 class="c8" id="h.h994f123ac23"><span class="c9">7.2.1 Pipeline&mdash; Model Evaluation </span></h2>
            <ol class="c23 lst-kix_m3nsaqjoeusd-0 start" start="1">
                <li class="c1 li-bullet-0"><span class="c3">Cleaned and preprocessed data in Jupyter then uploaded them
                        into ./data/cleaned/{date}/{dataset}-{train_or_test}-cleaned.csv</span></li>
                <li class="c1 li-bullet-0"><span class="c3">Run extraction and modeling from extract_and_model.py
                    </span></li>
            </ol>
            <ol class="c23 lst-kix_m3nsaqjoeusd-1 start" start="1">
                <li class="c6 c18 li-bullet-0"><span>Runs ./data/cleaned/{date}/{dataset}-{train_or_test}-cleaned.csv
                        through </span><span class="c3">extracting.py, file is saved to
                        ./data/extracted/{date}/{dataset}-{train_or_test}-{specific_feature_set}-extracted.csv</span>
                </li>
                <li class="c6 c18 li-bullet-0"><span class="c3">Runs
                        ./data/extracted/{dataset}-{train_or_test}-{specific_feature_set}-extracted.csv through
                        modeling.py, results &nbsp;is saved to
                        ./exploratory_analysis/{date}/{dataset}-{specific_feature_set}-extracted.csv </span></li>
            </ol>
            <ol class="c23 lst-kix_m3nsaqjoeusd-0" start="3">
                <li class="c1 li-bullet-0"><span class="c3">Download results and run it through a meta-data collector
                        function, organized by feature set with feature importances and model results, and name of the
                        dataset</span></li>
            </ol>
            <h2 class="c8" id="h.w0a2jam0iu5l"><span class="c9">7.2.2 Pipeline&mdash; Model Evaluation</span></h2>
            <ol class="c23 lst-kix_q6s6n33eh1zq-0 start" start="1">
                <li class="c1 li-bullet-0"><span class="c3">Cleaned and preprocessed data in Jupyter then uploaded them
                        into ./reddit/cleaned/{dataset}-cleaned.csv</span></li>
                <li class="c1 li-bullet-0"><span class="c3">Run extraction and modeling from extract_and_model.py
                    </span></li>
            </ol>
            <ol class="c23 lst-kix_q6s6n33eh1zq-1 start" start="1">
                <li class="c6 c18 li-bullet-0"><span class="c3">Runs <br>./reddit/cleaned/{dataset}-cleaned.csv through
                        extracting.py, file is saved to ./reddit/extracted/{dataset}-extracted-for-spam.csv</span></li>
                <li class="c6 c18 li-bullet-0"><span class="c3">Runs ./reddit/extracted/{dataset}-extracted-for-spam.csv
                        through extracting.py, Saves predicted spam results file to
                        ./reddit/predicted_spam/{dataset}-predicted_spam.csv</span></li>
                <li class="c6 c18 li-bullet-0"><span class="c3">Runs ./reddit/extracted/{dataset}-extracted-for-spam.csv
                        through modeling.py, Saves predicted spam results file to
                        ./reddit/predicted_spam/{dataset}-predicted_spam.csv</span></li>
                <li class="c6 c18 li-bullet-0"><span>Runs ./reddit/predicted_spam/{dataset}-predicted_spam.csv through
                    </span><span class="c16 c22"><a class="c20"
                            href="https://www.google.com/url?q=http://modeling.py&amp;sa=D&amp;source=editors&amp;ust=1765933959062151&amp;usg=AOvVaw21D6FVRzGZsOIOiLNbzVQb">modeling.py</a></span><span
                        class="c3">, </span></li>
            </ol>
            <ol class="c23 lst-kix_q6s6n33eh1zq-2 start" start="1">
                <li class="c6 c33 li-bullet-0"><span class="c3">Saves removed spam file to
                        &nbsp;./reddit/predicted_spam/{dataset}-removed_spam.csvt</span></li>
                <li class="c6 c33 li-bullet-0"><span class="c3">Saves predicted sentiment file (with original columns
                        from predicted_spam) to ./reddit/predicted_sentiment/{dataset}-predicted_sentiment</span></li>
            </ol>
            <ol class="c23 lst-kix_q6s6n33eh1zq-0" start="3">
                <li class="c1 li-bullet-0"><span class="c3">Download results and collect metadata</span></li>
            </ol>
            <p class="c5"><span class="c3"></span></p>
            <p class="c5"><span class="c3"></span></p>
            <p class="c5"><span class="c3"></span></p>
            <div>
                <p class="c42"><span class="c3"></span></p>
            </div>
        </div>
          </article>
        </div>

      <aside class="blog-rail" aria-label="Sidebar">
        <div class="rail-card">
          <div class="rail-title">On this page</div>
          <nav class="rail-nav" id="toc">
            <a href="#h.1ivn9olyl8ak">Introduction</a>
            <a href="#h.pmbj0cqwfcca">Methodology</a>
            <a href="#h.1ob5komhk1mq">Results</a>
            <a href="#h.j2ceh8yzupye">Lessons Learned</a>
            <a href="#h.abtrpam8ft2o">Bibliography</a>
            <a href="#h.utkmpokrzpm">Glossary of Terms</a>
            <a href="#h.h994f123ac23">Pipeline Overview</a>

          </nav>
        </div>

      </aside>

    <div class="post-footer">
          <p class="backline">
            <a class="back-link" href="/leannevu.github.io/blog/index.html">â† Back to Blog</a>
          </p>
        </div>
      </div>

    </div>
  </main>
</body>
</html>
